Joint statement following the meeting between the EGE and Smer in Stockholm on 
24 May 2023 

The European Group on Ethics in Science and New Technologies (EGE) and the Swedish National 

Council  on  Medical  Ethics  (Smer)  met  today,  24 May 2023,  to  discuss  ethical  issues  related  to 

disruptive and rapid digital developments, with a focus on ethical implications with particular regard 

to democracy, human rights and the future of health and healthcare. 

The EGE Opinion on “Democracy in the digital age” has been the starting point of the discussions. 

The Opinion stems from the request of the President of the European Commission, in the context of 

the  revision  of  the  European  Democracy  Action  Plan  and  of  the  development  of  the  Defence  of 

Democracy package. Overall, it analyses the challenges of the digital age and identifies measures to 

safeguard and promote democracy. 

The EGE Opinion focuses on the role of online platforms, politics, media, civil society organisations, 

universities and other actors in opinion-shaping. Looking to the future, it also explores the role that 

digital  technologies might  play  in  developing  wider  and  more  inclusive  civic  spaces  and enhancing 

public  participation.  It  is  informed  by  a  ‘thick’  (moral)  understanding  of  democracy  that  defines 

democracy  as  the  people’s  rule  underpinned  by  fundamental  rights  and  societal  values  such  as 

solidarity, equality and freedom. Protecting democracies, understood in such a comprehensive way, 

requires  strengthening  the  rule  of  the  people  in  a  way  that  is  broader  and  deeper  than  merely 

safeguarding free elections. 

The issues addressed in the EGE Opinion are also highly relevant for the future of health, healthcare 

and research. Smer has previously worked on issues related to digitalisation and artificial intelligence 

in  health  care  and  research.  It  has,  for  example,  presented  publications  on  self-monitoring  and 

wearables, artificial intelligence, health data and the use of robotics in health care. Issues related to 

digitalisation  and  democracy,  and  the  values  embedded  therein,  have  also  been  emphasised  in  the 

Council’s work during the pandemic. 

The pandemic has highlighted issues concerning democratic decision making, human rights and global 

justice, trust in science and information, and ultimately the ability of societies to cope with catastrophic 

       
 
 
events. Different digital tools (such as health apps and health surveillance) have been adopted at an 

increasingly  rapid  pace.  Digital  platforms  have  emerged  as  important  infrastructures  related  to 

democratic  values  in  society,  enabling  people  to  connect  across  countries  and  worldwide.  These 

platforms can be used as means to drive positive change on a global scale. However, the developments 

of recent years have demonstrated that digital platforms can both favourably and detrimentally affect 

democratic  discourse.  They  have  been  used  to  spread  harmful  information  and  drive  political 

polarisation.  This  has  harmed  public  health,  deepened  divisions  between  groups  in  society,  and 

damaged interpersonal trust. This  is particularly problematic when society faces major and difficult 

threats such as war, the climate crisis, and health crises like pandemics. 

Protecting democracy is an ongoing effort. Today, the norms and principles providing the foundations 

for human rights, democracy and the rule of law – on which the EU was built – are being called into 

question. Developments such as the rise of populist and nationalist movements, the growth of anti-

democratic sentiments, geopolitical threats from authoritarian rulers, and growing social and economic 

inequalities put a strain on democracy and its values. At the same time, digital capabilities continue to 

evolve, the most recent example of which was the launch of ChatGPT-3 and -4, the advanced language 

processing tools based on AI technologies, with unknown capacities. 

The future impact of AI technologies  is unpredictable  and  can pose  profound  risks  to  society  and 

humanity. Regulation that safeguards and strengthens human rights and democratic values is therefore 

fundamentally important. In healthcare, it is of key importance that alternative access to services is 

available to people who prefer not to use digital tools. Similarly, ‘consenting’ to sharing data must not 

become  a  precondition 

for  obtaining  access 

to  essential  services  such  as  healthcare. 

In its Opinion, the EGE highlights that the provision of public goods that satisfy basic needs, such as 

healthcare – which it describes as a precondition for a thriving democracy – should be insulated from 

market  rationales  and  dynamics.  Healthcare  should  remain  available  and  accessible  to  all  people 

independent of their ability to pay. People in need of healthcare need to be treated as patients, not 

consumers.  In  the digital era,  we  must  ensure  that people’s  basic  needs  do not  need to  be  met on 

market terms. 

In conclusion, the EGE and Smer jointly emphasise the following: 

We highlight that – especially in times of rapid technological change – ethics councils and committees 

remain of crucial importance for societies. One of their key roles is to provide ethical analysis, especially 

in the  context of governance and policy-making, in relation to the  development of our societies in 

general and the technological advances in society, medicine and healthcare, notably. 

We recognise that the pandemic, climate change, wars and natural disasters have challenged society and 

broadened the range of what we consider (bio)ethical questions. We call for efforts from all parts of 

society to stand up for human rights and democratic values to confront the challenges we are facing 

today. 

We also recognise the potential impacts of AI technologies and digital platforms on society. We strongly 

urge governments, authorities and other stakeholders to safeguard individual privacy and autonomy, 

and enhance the value that digital technology use creates for people and societies, rather than merely 

for companies. In this context, we welcome the ongoing efforts of governments and other stakeholders 

in the EU to introduce ethical considerations into the core of any future discussion and development 

of governance of AI and digitalisation – in health care and society as a whole. 

We  call  for  an  increased  effort  towards  the  creation  of  inclusive  digital  public  spaces  that  support 

respectful exchange and dialogue, as well as for stronger legal measures against the spread of mis- and 

disinformation. 

We strongly emphasise the importance of maintaining cooperation between ethics councils in different 

countries and on the European and global level. The European Group on Ethics in Science and New 

Technologies  and  the  Swedish  National  Council  on  Medical  Ethics  are  committed  to  such 

collaboration in the future.  

 
 
 
